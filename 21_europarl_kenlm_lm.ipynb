{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang=\"en\"  # change to your target lang\n",
    "speaker = \"M01\"\n",
    "model_name = \"yip-i/torgo_xlsr_finetune-\" + speaker\n",
    "speaker_to_filter_out = ['MC01', 'MC02', 'MC03', 'MC04','FC01','FC02','FC03']\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "username = \"jindaznb\"  # change to your username\n",
    "\n",
    "dataset = load_dataset(f\"{username}/{target_lang}_corpora_parliament_processed\", split=\"train\")\n",
    "\n",
    "with open(\"text.txt\", \"w\") as file:\n",
    "  file.write(\" \".join(dataset[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70b268e10ee494cb4e9a54d9cd325d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "!git config --global user.email \"jindaz.work@outlook.com\"\n",
    "!git config --global user.name \"j\"\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/torgo_error_correction/europarl_bilingual_kenlm_3-gram is already a clone of https://huggingface.co/jindaznb/europarl_bilingual_kenlm_3-gram. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "WARNING - /work/van-speech-nlp/jindaznb/jslpnb/torgo_error_correction/europarl_bilingual_kenlm_3-gram is already a clone of https://huggingface.co/jindaznb/europarl_bilingual_kenlm_3-gram. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Repository jindaznb/europarl_bilingual_kenlm_3-gram already exists.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import create_repo, Repository\n",
    "\n",
    "try:\n",
    "  repo = Repository(repo_path_local, clone_from=repo_path_remote)\n",
    "  print(f\"\\nRepository {repo_path_remote} already exists.\")\n",
    "except:\n",
    "  create_repo(repo_path_remote, exist_ok=True)\n",
    "  repo = Repository(repo_path_local, clone_from=repo_path_remote)\n",
    "  print(\"\\nRepository created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b3bb478d0d4ec9bd61e31194d3dcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/283 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/zhang.jinda1/.cache/huggingface/datasets/jindaznb___parquet/jindaznb--en_corpora_parliament_processed-063cb73b5f63b162/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1986b86c2b324a7cbcf9a6d00867f6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a20fbfa7b494b82afa372aebbf16dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/172M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70204868b39e4c819c391cd99e1167a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2051014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/zhang.jinda1/.cache/huggingface/datasets/jindaznb___parquet/jindaznb--en_corpora_parliament_processed-063cb73b5f63b162/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2051014\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europarl = load_dataset(f\"{username}/{target_lang}_corpora_parliament_processed\", split=\"train\")\n",
    "europarl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train wordlevel ngram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kenlm/build/bin/lmplz -o 3    --text europarl.txt     --arpa {repo_path_local}/output_model.klm_trigram.arpa     --discount_fallback --skip_symbols|     kenlm/build/bin/build_binary     -T /dev/stdin {repo_path_local}/output_model.klm_trigram.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/van-speech-nlp/jindaznb/jslpnb/torgo_error_correction/text.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 51495092 types 127507\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:1530084 2:10480902144 3:19651692544 4:31442706432 5:45853949952\n",
      "Statistics:\n",
      "1 127506 D1=0.648223 D2=1.00063 D3+=1.40113\n",
      "2 3731487 D1=0.712145 D2=1.06726 D3+=1.38333\n",
      "3 16334069 D1=0.801852 D2=1.11912 D3+=1.36491\n",
      "4 31609785 D1=0.880996 D2=1.19342 D3+=1.38133\n",
      "5 41878656 D1=0.91918 D2=1.23229 D3+=1.33838\n",
      "Memory estimate for binary LM:\n",
      "type      MB\n",
      "probing 1904 assuming -p 1.5\n",
      "probing 2200 assuming -r models -p 1.5\n",
      "trie     892 without quantization\n",
      "trie     488 assuming -q 8 -b 8 quantization \n",
      "trie     782 assuming -a 22 array pointer compression\n",
      "trie     378 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:1530072 2:59703792 3:326681380 4:758634840 5:1172602368\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:1530072 2:59703792 3:326681380 4:758634840 5:1172602368\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:105067632 kB\tVmRSS:7440 kB\tRSSMax:19682988 kB\tuser:94.2164\tsys:44.9199\tCPU:139.136\treal:121.158\n"
     ]
    }
   ],
   "source": [
    "!kenlm/build/bin/lmplz -o 5 <\"text.txt\" > \"5gram.arpa\" --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\data\\\n",
      "ngram 1=46\n",
      "ngram 2=1430\n",
      "ngram 3=27526\n",
      "ngram 4=267526\n",
      "ngram 5=1334843\n",
      "\n",
      "\\1-grams:\n",
      "-3.0126686\t<unk>\t0\n",
      "0\t<s>\t-4.5599556\n",
      "-1.612649\t</s>\t0\n",
      "-1.5884404\tR\t-1.4659708\n",
      "-1.5655105\tIH\t-1.564043\n",
      "-1.600376\tZ\t-1.5807759\n",
      "-1.5544841\tAH\t-1.6780617\n",
      "-1.5768242\tM\t-1.5517106\n",
      "-1.5768242\tP\t-1.5669491\n",
      "-1.5884404\tSH\t-1.442344\n",
      "-1.5768242\tN\t-1.5247967\n",
      "-1.5884404\tV\t-1.4767572\n"
     ]
    }
   ],
   "source": [
    "!head -20 5gram.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"5gram.arpa\", \"r\") as read_file, open(\"5gram_correct.arpa\", \"w\") as write_file:\n",
    "#   has_added_eos = False\n",
    "#   for line in read_file:\n",
    "#     if not has_added_eos and \"ngram 1=\" in line:\n",
    "#       count=line.strip().split(\"=\")[-1]\n",
    "#       write_file.write(line.replace(f\"{count}\", f\"{int(count)+1}\"))\n",
    "#     elif not has_added_eos and \"<s>\" in line:\n",
    "#       write_file.write(line)\n",
    "#       write_file.write(line.replace(\"<s>\", \"</s>\"))\n",
    "#       has_added_eos = True\n",
    "#     else:\n",
    "#       write_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading europarl_bilingual_kenlm_3-gram/output_model.klm_trigram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "if ngram_order > 1:\n",
    "  !kenlm/build/bin/build_binary {repo_path_local}/output_model.klm_trigram.arpa {repo_path_local}/output_model.klm_trigram.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fb2302d2a74666aa0d8ed4219acd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file output_model.klm_trigram_raw.bin:   1%|          | 3.28k/519k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/jindaznb/europarl_bilingual_kenlm_3-gram\n",
      "   0de756c..d62b286  main -> main\n",
      "\n",
      "WARNING - To https://huggingface.co/jindaznb/europarl_bilingual_kenlm_3-gram\n",
      "   0de756c..d62b286  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/jindaznb/europarl_bilingual_kenlm_3-gram/commit/d62b2865e075145c34c988f7851aa6fa23f5ff3b'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.push_to_hub(commit_message=\"Upload n-gram model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "test_speaker = \"M01\"\n",
    "model_user = \"macarious\"\n",
    "model_repo = f\"torgo_xlsr_finetune_{test_speaker}\"\n",
    "model_name = f\"{model_user}/{model_repo}\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /work/van-speech-nlp/jindaznb/jslpnb/torgo_error_correction/5gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "Unigrams and labels don't seem to agree.\n",
      "Only 46 unigrams passed as vocabulary. Is this small or artificial data?\n"
     ]
    }
   ],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "decoder = build_ctcdecoder(\n",
    "    labels=list(sorted_vocab_dict.keys()),\n",
    "    kenlm_model_path=\"5gram.arpa\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ProcessorWithLM\n",
    "\n",
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    decoder=decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/macarious/torgo_xlsr_finetune_M01 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243f057ec2ae454c84e4800a871387c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 3.45k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b942cae45a6e4629810b5eb634c11085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Jan25_00-36-00_d1005/events.out.tfevents.1706161084.d1005.11790.0:  17%|#7        | 3.45k/1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dfd86fbc3548e09ea076c701221586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Jan25_00-36-00_d1005/1706161084.7326531/events.out.tfevents.1706161084.d1005.11790.1:  61%|…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076fd573c1e947d089360e8baa2f9582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Nov20_19-57-17_0f53531ac0df/events.out.tfevents.1700510385.0f53531ac0df.52655.0:  11%|#    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07250142fc18408baf065c2346c3cb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Nov20_19-05-29_0f53531ac0df/events.out.tfevents.1700507302.0f53531ac0df.321.3:  28%|##8    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f97f5440c04afbb048369f695fa3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Jan24_17-40-23_d1005/events.out.tfevents.1706136138.d1005.108367.0:  42%|####2     | 8.24k/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155a6107b02f4f29a87a23b2c77f2b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Jan24_17-40-23_d1005/1706136138.9474404/events.out.tfevents.1706136138.d1005.108367.1:  61%…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf6de2d0a874e2787da59f1ed1c173d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Nov20_19-05-29_0f53531ac0df/1700507302.8993618/events.out.tfevents.1700507302.0f53531ac0df.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce68e6a557546d2bf3bb7ac50c6acbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Nov20_19-05-29_0f53531ac0df/1700507598.2107837/events.out.tfevents.1700507598.0f53531ac0df.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a554393e7749cca4f181c60169b70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Nov20_19-57-17_0f53531ac0df/1700510385.488164/events.out.tfevents.1700510385.0f53531ac0df.5…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e40d6528674c0b818cfb6c4d5cae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin:  89%|########9 | 3.46k/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a49d1b7a1904be3ad94dbe79cdb16aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Nov20_19-57-17_0f53531ac0df/events.out.tfevents.1700510385.0f53531ac0df.52655.0:   3%|3       …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b9aeb5e39349cd8dea26ef9f9fa13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Nov20_19-57-17_0f53531ac0df/1700535469.8101287/events.out.tfevents.1700535469.0f53531ac0df.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b66f7f737124a3db8560319e474e662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Jan25_00-36-00_d1005/events.out.tfevents.1706161084.d1005.11790.0:   5%|5         | 1.00k/19.8…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba510b524b14456977765fe6fc33d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Jan25_00-36-00_d1005/1706161084.7326531/events.out.tfevents.1706161084.d1005.11790.1:  18%|#7 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6274282d378143e68566aa026d1f1e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Nov20_19-05-29_0f53531ac0df/events.out.tfevents.1700507302.0f53531ac0df.321.3:   8%|8         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bba79c3ff71472c8118080f49d538ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Jan24_17-40-23_d1005/1706136138.9474404/events.out.tfevents.1706136138.d1005.108367.1:  18%|#7…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f9ff3d3935406e98fd1c78de8b7add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Jan24_17-40-23_d1005/events.out.tfevents.1706136138.d1005.108367.0:   5%|5         | 1.00k/19.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11420f4dd7b64e20b91a88f02096103f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Nov20_19-05-29_0f53531ac0df/1700507302.8993618/events.out.tfevents.1700507302.0f53531ac0df.321…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92db57ceffda4151977ab3d5c5ecf69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Nov20_19-05-29_0f53531ac0df/1700507598.2107837/events.out.tfevents.1700507598.0f53531ac0df.321…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da07a16f78914eaf94015ed890813403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Nov20_19-57-17_0f53531ac0df/1700510385.488164/events.out.tfevents.1700510385.0f53531ac0df.5265…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04747525a8224b54a8fe9113f9216293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  26%|##5       | 1.00k/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b898bfe5fa415dbd8f06672fedd5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Nov20_19-57-17_0f53531ac0df/1700535469.8101287/events.out.tfevents.1700535469.0f53531ac0df.526…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d7e76ede6549498a94fb30afec8b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "repo = Repository(local_dir=\"model_staging\", clone_from=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_with_lm.save_pretrained(\"model_staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('torgo.csv')\n",
    "df['audio'] = df['audio'].apply(lambda x: f\"/work/van-speech-nlp/data/torgo/{x}\")\n",
    "df.to_csv('torgo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
